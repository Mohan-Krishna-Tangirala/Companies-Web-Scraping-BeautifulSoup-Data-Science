# Web Scraping Project: Extracting Data from Wikipedia

## Website link : "https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue"

## Overview

This project demonstrates how to scrape data from a real website and load it into a Pandas DataFrame using Python. 

We specifically extract information from Wikipedia's list of the largest companies in the United States by revenue. 

The final output can be exported to a CSV file for further analysis.

## Objectives

- Scrape data from a Wikipedia table.
- Load the data into a Pandas DataFrame.
- Export the DataFrame to a CSV file.

## Technologies Used

- **Python**: The primary programming language used for web scraping and data manipulation.
- **BeautifulSoup**: A library for parsing HTML and XML documents.
- **Requests**: A library for making HTTP requests to fetch web content.
- **Pandas**: A library for data manipulation and analysis.

## Conclusion

In this project, we successfully scraped data from a Wikipedia table, organized it into a Pandas DataFrame, and exported it to a CSV file. 

This process involved several steps, including importing libraries, fetching and parsing HTML, and handling data extraction and cleaning.

## Feel free to dive into the code and data to uncover insights into the exciting world of web scraping and data analysis!
